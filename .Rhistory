(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,2] == 1),
(train_y_label.iloc[:,1] == 1),
(train_y_label.iloc[:,0] == 1)
]
choices=[1,2,3,4,5,6,7,8,9,10,11,12]
train_y_label['class'] = np.select(conditions, choices, default=0)
train_y_label.groupby('class').size()
train_y_label
train_y_label
train_y_label=train.iloc[:,294:]
train=train.drop([train_y_label.columns[0],train_y_label.columns[1],train_y_label.columns[2],train_y_label.columns[3],train_y_label.columns[4],train_y_label.columns[5]], axis=1)
import numpy as np
import numpy as np
conditions = [
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,2] == 1),
(train_y_label.iloc[:,1] == 1),
(train_y_label.iloc[:,0] == 1)
]
choices=[1,2,3,4,5,6,7,8,9,10,11,12]
train_y_label['class'] = np.select(conditions, choices, default=0)
train_y_label=train.iloc[:,294:]
train=train.drop([train_y_label.columns[0],train_y_label.columns[1],train_y_label.columns[2],train_y_label.columns[3],train_y_label.columns[4],train_y_label.columns[5]], axis=1)
train
train_y_label
import os
os.getcwd()
import pandas as pd
train=pd.read_csv("train.csv",header=None)
train.iloc[:,294:].head()
train.columns[294]
train_2 = train.iloc[:,294:]
train_2.head()
train_2.columns
train_2.groupby([train_2.columns[0],train_2.columns[1],train_2.columns[2],train_2.columns[3],train_2.columns[4],train_2.columns[5]
]).agg({
train_2.columns[0]: 'count',train_2.columns[1]: 'count',train_2.columns[2]: 'count',train_2.columns[3]: 'count',train_2.columns[4]: 'count',train_2.columns[5]: 'count'
})
train_y_label=train.iloc[:,294:]
train_y_label
train=train.drop([train_y_label.columns[0],train_y_label.columns[1],train_y_label.columns[2],train_y_label.columns[3],train_y_label.columns[4],train_y_label.columns[5]], axis=1)
import numpy as np
conditions = [
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,2] == 1),
(train_y_label.iloc[:,1] == 1),
(train_y_label.iloc[:,0] == 1)
]
choices=[1,2,3,4,5,6,7,8,9,10,11,12]
train_y_label['class'] = np.select(conditions, choices, default=0)
train_y_label.groupby('class').size()
train_y_label
from sklearn.linear_model import LogisticRegression
y=train_y_label['class']
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn import svm
X, y = datasets.load_iris(return_X_y=True)
X.shape, y.shape
from sklearn.linear_model import LogisticRegression
quit
library(reticulate)
py_install("sklearn")
reticulate::repl_python()
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LogisticRegression
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn import svm
X, y = datasets.load_iris(return_X_y=True)
X.shape, y.shape
X
y
X_train, X_test, y_train, y_test = train_test_split(
X, y, test_size=0.4, random_state=0)
X_train
X_test
y_train
X_train.shape, y_train.shape
X_test.shape, y_test.shape
clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
clf.score(X_test, y_test)
clf = svm.SVC(kernel='linear', C=5).fit(X_train, y_train)
clf.score(X_test, y_test)
clf = svm.SVC(kernel='linear', C=5).fit(X_train, y_train)
clf.score(X_test, y_test)
clf = svm.SVC(kernel='linear', C=1)
scores = cross_val_score(clf, X, y, cv=5)
scores
from sklearn.model_selection import cross_val_score
clf = svm.SVC(kernel='linear', C=1)
scores = cross_val_score(clf, X, y, cv=5)
scores
clf
import numpy as np
from sklearn.model_selection import KFold
X = ["a", "b", "c", "d"]
kf = KFold(n_splits=2)
kf
kf.split(X)
print("%s %s" % (train, test))
for train, test in kf.split(X):
print("%s %s" % (train, test))
print("%s %s" % (train, test))
for train, test in kf.split(X):
print("%s %s" % (train, test))
import numpy as np
from sklearn.model_selection import RepeatedKFold
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
random_state = 12883823
X
rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=random_state)
rkf
for train, test in rkf.split(X):
print("%s %s" % (train, test))
import numpy as np
from scipy import interp
import matplotlib.pyplot as plt
from sklearn import svm, datasets
from sklearn.metrics import auc
from sklearn.metrics import plot_roc_curve
from sklearn.model_selection import StratifiedKFold
iris = datasets.load_iris()
iris
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
n_samples
X
y
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
X
cv = StratifiedKFold(n_splits=6)
cv = StratifiedKFold(n_splits=6)
classifier = svm.SVC(kernel='linear', probability=True,
random_state=random_state)
classifier
cv
cv.split(X, y)
enumerate(cv.split(X, y))
tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)
fig, ax = plt.subplots()
enumerate(cv.split(X, y))
classifier.fit(X[train], y[train])
import matplotlib.pyplot as plt
py_install("matplotlib")
quit
library(reticulate)
py_install("matplotlib")
2+2
reticulate::repl_python()
import matplotlib.pyplot as plt
import numpy as np
from scipy import interp
import matplotlib.pyplot as plt
from sklearn import svm, datasets
from sklearn.metrics import auc
from sklearn.metrics import plot_roc_curve
from sklearn.model_selection import StratifiedKFold
# #############################################################################
# Data IO and generation
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
cv = StratifiedKFold(n_splits=6)
classifier = svm.SVC(kernel='linear', probability=True,
random_state=random_state)
enumerate(cv.split(X, y))
tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)
fig, ax = plt.subplots()
classifier.fit(X[train], y[train])
for i, (train, test) in enumerate(cv.split(X, y)):
classifier.fit(X[train], y[train])
viz = plot_roc_curve(classifier, X[test], y[test],
name='ROC fold {}'.format(i),
alpha=0.3, lw=1, ax=ax)
interp_tpr = interp(mean_fpr, viz.fpr, viz.tpr)
interp_tpr[0] = 0.0
tprs.append(interp_tpr)
aucs.append(viz.roc_auc)
cv = StratifiedKFold(n_splits=4)
classifier = svm.SVC(kernel='linear', probability=True,
random_state=random_state)
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
# Run classifier with cross-validation and plot ROC curves
cv = StratifiedKFold(n_splits=4)
classifier = svm.SVC(kernel='linear', probability=True,
random_state=random_state)
for  i, (train, test) in enumerate(cv.split(X, y)):
print(X[train], y[train])
y
import os
os.getcwd()
import pandas as pd
train=pd.read_csv("train.csv",header=None)
train.iloc[:,294:].head()
train.columns[294]
train_2 = train.iloc[:,294:]
train_2.head()
train_2.columns
train_2.groupby([train_2.columns[0],train_2.columns[1],train_2.columns[2],train_2.columns[3],train_2.columns[4],train_2.columns[5]
]).agg({
train_2.columns[0]: 'count',train_2.columns[1]: 'count',train_2.columns[2]: 'count',train_2.columns[3]: 'count',train_2.columns[4]: 'count',train_2.columns[5]: 'count'
})
train_y_label=train.iloc[:,294:]
train=train.drop([train_y_label.columns[0],train_y_label.columns[1],train_y_label.columns[2],train_y_label.columns[3],train_y_label.columns[4],train_y_label.columns[5]], axis=1)
import numpy as np
conditions = [
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,3] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,2] == 1) & (train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,0] == 1) & (train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,5] == 1),
(train_y_label.iloc[:,4] == 1),
(train_y_label.iloc[:,3] == 1),
(train_y_label.iloc[:,2] == 1),
(train_y_label.iloc[:,1] == 1),
(train_y_label.iloc[:,0] == 1)
]
choices=[1,2,3,4,5,6,7,8,9,10,11,12]
train_y_label['class'] = np.select(conditions, choices, default=0)
train_y_label.groupby('class').size()
y=train_y_label['class']
y
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
# #############################################################################
# Classification and ROC analysis
# Run classifier with cross-validation and plot ROC curves
cv = StratifiedKFold(n_splits=4)
classifier = svm.SVC(kernel='linear', probability=True,
random_state=random_state)
enumerate(cv.split(X, y))
tprs = []
aucs = []
mean_fpr = np.linspace(0, 1, 100)
fig, ax = plt.subplots()
classifier.fit(X[train], y[train])
for  i, (train, test) in enumerate(cv.split(X, y)):
print(X[train], y[train])
from sklearn.linear_model import LogisticRegression
X[train]
LogisticRegression(random_state=777).fit(X[train], y[train])
from sklearn import datasets, linear_model
from sklearn.model_selection import cross_val_predict
diabetes = datasets.load_diabetes()
X = diabetes.data[:150]
y = diabetes.target[:150]
lasso = linear_model.Lasso()
y_pred = cross_val_predict(lasso, X, y, cv=3)
y_pred
import numpy as np
from sklearn.model_selection import KFold
X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
y = np.array([1, 2, 3, 4])
kf = KFold(n_splits=2)
kf.get_n_splits(X)
print(kf)
for train_index, test_index in kf.split(X):
print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
X
y
kf = KFold(n_splits=3)
kf.get_n_splits(X)
for train_index, test_index in kf.split(X):
print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
for train_index, test_index in kf.split(X):
print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
clf=LogisticRegression(random_state=777).fit(X[train], y[train])
clf
X_test
clf.predict(X_test)
y_test
from sklearn.metrics import accuracy_score
accuracy_score(y_test, clf.predict(X_test))
kf = KFold(n_splits=3)
kf.get_n_splits(X)
# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target
X, y = X[y != 2], y[y != 2]
n_samples, n_features = X.shape
# Add noisy features
random_state = np.random.RandomState(0)
X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]
from sklearn.metrics import accuracy_score
print(kf)
for train_index, test_index in kf.split(X):
print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
clf=LogisticRegression(random_state=777).fit(X[train], y[train])
accuracy_score(y_test, clf.predict(X_test))
for train_index, test_index in kf.split(X):
print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
clf=LogisticRegression(random_state=777).fit(X[train], y[train])
print(accuracy_score(y_test, clf.predict(X_test)))
print(accuracy_score(y_test, clf.predict(X_test)))
for train_index, test_index in kf.split(X):
#print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
clf=LogisticRegression(random_state=777).fit(X[train], y[train])
print(accuracy_score(y_test, clf.predict(X_test)))
kf = KFold(n_splits=5)
kf.get_n_splits(X)
for train_index, test_index in kf.split(X):
#print("TRAIN:", train_index, "TEST:", test_index)
X_train, X_test = X[train_index], X[test_index]
y_train, y_test = y[train_index], y[test_index]
clf=LogisticRegression(random_state=777).fit(X[train], y[train])
print(accuracy_score(y_test, clf.predict(X_test)))
1+1+0.95+1+0.75
mean(1+1+0.95+1+0.75)
np.mean(1+1+0.95+1+0.75)
np.mean(1,1,0.95,1,0.75)
np.mean([1,1,0.95,1,0.75])
clf=LogisticRegression(random_state=777).fit(X, y)
print(accuracy_score(y, clf.predict(X)))
n_samples
X
X = iris.data
X
X.shape
random.uniform(0, 20)
import random
random.uniform(0, 20)
random.randint(0, 149)
for i in range(50):
reticulate::repl_python()
slc=[]
for i in range(50):
slc.append(random.randint(0, 149))
slc
X[slc]
X_slc=X[slc]
y_slc=y[slc]
y = iris.target
y
y.shape
y_slc=y[slc]
X[slc]
-X[slc]
X[-slc]
X[!slc]
X[slc]
X!=X[slc]
X[X!=X[slc]]
X[X!=X[slc]].shape
X[X!=X[slc]]
X[X==X[slc]]
X[X==X[slc]]
X.shape
del X[slc]
slc
np.delete(arr, slc)
np.delete(X, slc)
x.Shape
X.shape
X=np.delete(X, slc)
X.shape
X.shape
X
X = iris.data
y = iris.target
slc=[]
for i in range(50):
slc.append(random.randint(0, 149))
X_slc=X[slc]
y_slc=y[slc]
X.shape
X
X.dtype
X.dtype()
X[slc]
slc
import random
spisok = ["Love", "World", "Peace", "Putin",]
spisok
random.shuffle(spisok)
print spisok
print(spisok)
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
random.shuffle(spisok,random=777)
print(spisok)
import random
seed(777)
spisok = ["Love", "World", "Peace", "Putin",]
random.shuffle(spisok)
print(spisok)
import random
seed(777)
spisok = ["Love", "World", "Peace", "Putin",]
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
seed(777)
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
seed(777)
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
random.seed(777)
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
random.seed(777)
random.shuffle(spisok)
print(spisok)
import random
spisok = ["Love", "World", "Peace", "Putin",]
random.seed(777)
random.shuffle(spisok)
print(spisok)
iris = datasets.load_iris()
X = iris.data
y = iris.target
random.seed(777)
X=random.shuffle(X)
random.seed(777)
Y=random.shuffle(Y)
iris = datasets.load_iris()
X = iris.data
y = iris.target
random.seed(777)
X=random.shuffle(X)
random.seed(777)
y=random.shuffle(y)
y
y
y
2+2
y
